const sharp = require('sharp');
const os = require('os');
const AIEnhancer = require('./ai-enhancer');

// Import GPU acceleration components
const GPUAcceleratedProcessor = require('./gpu-accelerated-processor');

class ImageProcessor {
    constructor() {
        console.log('üîß Configuring Sharp for memory-optimized performance...');
        
        // Memory-optimized Sharp configuration
        sharp.cache({
            memory: 50, // 50MB cache limit
            files: 20,  // Max 20 files in cache
            items: 100  // Max 100 cache items
        });
        
        // Force garbage collection more frequently for large images
        if (global.gc) {
            console.log('üóëÔ∏è Manual garbage collection available');
        }
        
        this.systemInfo = {
            cpuCount: os.cpus().length,
            totalMemory: os.totalmem(),
            freeMemory: os.freemem(),
            platform: os.platform()
        };
        
        // Initialize AI enhancer
        this.aiEnhancer = new AIEnhancer();
        
        // Initialize GPU acceleration
        this.gpuProcessor = null;
        this.gpuAvailable = false;
        this.hardwareDetector = null;
        
        // Initialize CPU tiled processor (fallback for large images)
        this.cpuTiledProcessor = null;
        
        // Initialize GPU acceleration (will be completed in initialize())
        this.gpuInitialized = false;
        
        console.log('üíª System info:', {
            cpus: this.systemInfo.cpuCount,
            memory: `${Math.round(this.systemInfo.totalMemory / 1024 / 1024 / 1024)}GB`,
            free: `${Math.round(this.systemInfo.freeMemory / 1024 / 1024 / 1024)}GB`,
            platform: this.systemInfo.platform
        });
        
        console.log('‚úÖ Sharp configured for memory optimization');
        console.log('üì¶ Sharp version:', sharp.versions);
    }
    
    async initialize() {
        // Initialize GPU acceleration and CPU tiled processor
        if (!this.gpuInitialized) {
            await this.initializeGPUAcceleration();
            this.gpuInitialized = true;
        }
        console.log('üîß ImageProcessor initialized with debug mode enabled');
        return Promise.resolve();
    }
    
    optimizeMemoryForImageSize(targetPixels) {
        // Adjust memory settings based on image size
        const estimatedMemoryMB = Math.round(targetPixels * 4 / 1024 / 1024); // 4 bytes per pixel estimate
        
        if (targetPixels > 800000000) {
            // Extremely large images (800MP+): Ultra-conservative memory management
            sharp.cache({ memory: 10, files: 2, items: 10 });
            console.log(`üß† Extreme image memory optimization: Ultra-conservative cache (est. ${estimatedMemoryMB}MB needed)`);
            return 'ultra-aggressive';
        } else if (targetPixels > 400000000) {
            // Very large images: Aggressive memory management
            sharp.cache({ memory: 25, files: 5, items: 20 });
            console.log(`üß† Large image memory optimization: Conservative cache (est. ${estimatedMemoryMB}MB needed)`);
            return 'aggressive';
        } else if (targetPixels > 150000000) {
            // Medium images: Balanced memory management
            sharp.cache({ memory: 50, files: 10, items: 50 });
            console.log(`üß† Medium image memory optimization: Balanced cache (est. ${estimatedMemoryMB}MB needed)`);
            return 'balanced';
        } else {
            // Smaller images: Standard memory management
            sharp.cache({ memory: 100, files: 20, items: 100 });
            console.log(`üß† Standard image memory optimization: Full cache (est. ${estimatedMemoryMB}MB needed)`);
            return 'standard';
        }
    }
    
    async forceGarbageCollection() {
        // Force garbage collection if available
        if (global.gc) {
            const memBefore = process.memoryUsage().heapUsed / 1024 / 1024;
            global.gc();
            const memAfter = process.memoryUsage().heapUsed / 1024 / 1024;
            console.log(`üóëÔ∏è Garbage collection: ${memBefore.toFixed(1)}MB ‚Üí ${memAfter.toFixed(1)}MB (freed ${(memBefore - memAfter).toFixed(1)}MB)`);
        }
    }
    
    getMemoryOptimizedSharpOptions(targetPixels, isIntermediateStep = false) {
        // Conservative Sharp options to avoid failures while maintaining performance
        const baseOptions = {
            limitInputPixels: false,
            sequentialRead: true,
            failOnError: false
        };
        
        // Use minimal, safe options to prevent step failures
        // Memory optimization comes from cache management, not risky Sharp options
        return baseOptions;
    }
    
    getStreamOptimizedOutputOptions(outputSettings, isIntermediateStep = false) {
        // Optimize output options for streaming and memory efficiency
        if (isIntermediateStep) {
            // Intermediate steps: Minimal compression for speed
            return {
                format: 'png',
                options: {
                    compressionLevel: 0,    // No compression for speed
                    adaptiveFiltering: false,
                    palette: false
                }
            };
        } else if (outputSettings.format === 'jpeg') {
            // Final JPEG: Memory-optimized settings
            return {
                format: 'jpeg',
                options: {
                    ...outputSettings.options,
                    optimiseCoding: true,   // Better compression
                    mozjpeg: true          // Use mozjpeg if available
                }
            };
        } else if (outputSettings.format === 'tiff') {
            // Final TIFF: High-quality settings
            return {
                format: 'tiff',
                options: {
                    ...outputSettings.options,
                    compression: 'lzw',     // Efficient lossless compression
                    quality: 95,            // High quality
                    predictor: 'horizontal', // Better compression for natural images
                    tile: false,            // Don't use tiled format for compatibility
                    pyramid: false          // Don't use pyramid format
                }
            };
        } else {
            // Final PNG: Balanced settings
            return {
                format: 'png',
                options: {
                    ...outputSettings.options,
                    palette: false,         // No palette for large images
                    effort: 1              // Low effort for speed
                }
            };
        }
    }
    
    async processImageProgressiveOptimized(imageBuffer, metadata, targetScale, outputSettings, resizeSettings, onProgress) {
        console.log('üîÑ Starting memory-optimized progressive scaling...');
        
        const steps = this.calculateProgressiveSteps(1, targetScale);
        let currentBuffer = imageBuffer;
        let currentWidth = metadata.width;
        let currentHeight = metadata.height;
        
        console.log(`üîÑ Progressive scaling: ${steps.length} steps total (memory-optimized)`);
        
        // Process each step with memory optimization
        for (let i = 0; i < steps.length; i++) {
            const stepScale = steps[i];
            const stepWidth = Math.round(metadata.width * stepScale);
            const stepHeight = Math.round(metadata.height * stepScale);
            const stepPixels = stepWidth * stepHeight;
            const isIntermediateStep = i < steps.length - 1;
            
            console.log(`üîÑ Step ${i + 1}/${steps.length}: ${currentWidth}√ó${currentHeight} ‚Üí ${stepWidth}√ó${stepHeight} (${(stepPixels/1000000).toFixed(1)}MP)`);
            
            // Memory optimization before each step
            const memoryStrategy = this.optimizeMemoryForImageSize(stepPixels);
            await this.forceGarbageCollection();
            
            const stepStart = Date.now();
            
            // Get optimized options for this step
            const sharpOptions = this.getMemoryOptimizedSharpOptions(stepPixels, isIntermediateStep);
            const stepResizeSettings = this.getStepResizeSettings(stepPixels, resizeSettings);
            
            // Create memory-optimized Sharp instance with safe options
            const sharpInstance = sharp(currentBuffer, sharpOptions)
                .resize(stepWidth, stepHeight, stepResizeSettings);
            
            // Apply appropriate output format for this step
            if (isIntermediateStep) {
                // Intermediate step: Use fastest possible output
                currentBuffer = await sharpInstance
                    .png({
                        compressionLevel: 0,
                        adaptiveFiltering: false
                    })
                    .toBuffer();
            } else {
                // Final step: Use optimal output format
                const streamOptions = this.getStreamOptimizedOutputOptions(outputSettings, false);
                
                if (streamOptions.format === 'jpeg') {
                    currentBuffer = await sharpInstance
                        .jpeg(streamOptions.options)
                        .toBuffer();
                } else if (streamOptions.format === 'tiff') {
                    currentBuffer = await sharpInstance
                        .tiff(streamOptions.options)
                        .toBuffer();
                } else {
                    currentBuffer = await sharpInstance
                        .png(streamOptions.options)
                        .toBuffer();
                }
            }
            
            const stepTime = Date.now() - stepStart;
            const memoryUsage = process.memoryUsage();
            const progressPercent = Math.round(((i + 1) / steps.length) * 70) + 30;
            
            console.log(`‚úÖ Step ${i + 1} completed in ${stepTime}ms (${(stepPixels / stepTime * 1000 / 1000000).toFixed(1)}MP/s)`);
            console.log(`üß† Memory usage: ${(memoryUsage.heapUsed / 1024 / 1024).toFixed(1)}MB heap, ${(memoryUsage.rss / 1024 / 1024).toFixed(1)}MB RSS`);
            
            // Update progress
            onProgress?.({ 
                stage: 'processing', 
                progress: progressPercent,
                step: i + 1,
                totalSteps: steps.length,
                memoryMB: Math.round(memoryUsage.heapUsed / 1024 / 1024),
                currentScale: stepScale.toFixed(2),
                processingRate: `${(stepPixels / stepTime * 1000 / 1000000).toFixed(1)}MP/s`
            });
            
            // Processing delay removed for maximum speed
            
            currentWidth = stepWidth;
            currentHeight = stepHeight;
            
            // Force cleanup after large steps
            if (stepPixels > 200000000) {
                await this.forceGarbageCollection();
            }
        }
        
        // Final cleanup
        await this.forceGarbageCollection();
        console.log('‚úÖ Memory-optimized progressive scaling completed');
        
        // Return in consistent format
        return {
            buffer: currentBuffer,
            format: outputSettings.format,
            extension: outputSettings.extension
        };
    }
    
    getOptimalConcurrency(targetPixels) {
        const cpuCount = this.systemInfo.cpuCount;
        
        let optimalConcurrency;
        
        if (targetPixels > 500000000) {
            optimalConcurrency = Math.max(1, Math.floor(cpuCount / 2));
            console.log(`üßµ Large image (${(targetPixels/1000000).toFixed(0)}MP): Conservative concurrency = ${optimalConcurrency}`);
        } else if (targetPixels > 200000000) {
            optimalConcurrency = Math.max(2, cpuCount - 1);
            console.log(`üßµ Medium image (${(targetPixels/1000000).toFixed(0)}MP): Balanced concurrency = ${optimalConcurrency}`);
        } else {
            optimalConcurrency = cpuCount;
            console.log(`üßµ Standard image (${(targetPixels/1000000).toFixed(0)}MP): Full concurrency = ${optimalConcurrency}`);
        }
        
        return optimalConcurrency;
    }
    
    getOptimalOutputSettings(targetPixels, originalFormat, userPreferences = {}) {
        let outputSettings;
        
        // User format preference takes priority over automatic selection
        if (userPreferences.outputFormat) {
            console.log(`üë§ User requested format: ${userPreferences.outputFormat.toUpperCase()}`);
            return this.getUserPreferredOutputSettings(userPreferences.outputFormat, targetPixels, userPreferences);
        }
        
        // If original format is TIFF and high quality is needed, preserve TIFF for professional workflows
        if (originalFormat && (originalFormat.toLowerCase().includes('tiff') || originalFormat.toLowerCase().includes('tif')) && targetPixels <= 200000000) {
            outputSettings = {
                format: 'tiff',
                options: {
                    compression: 'lzw',
                    quality: 95,
                    predictor: 'horizontal',
                    tile: false,
                    pyramid: false
                },
                extension: 'tiff'
            };
            console.log(`üìÅ TIFF preservation (${(targetPixels/1000000).toFixed(0)}MP): High-quality TIFF format`);
            
        } else if (targetPixels > 300000000) {
            outputSettings = {
                format: 'jpeg',
                options: {
                    quality: 85,
                    progressive: true,
                    optimiseScans: true,
                    overshootDeringing: false,
                    trellisQuantisation: false
                },
                extension: 'jpg'
            };
            console.log(`üìÅ Large image (${(targetPixels/1000000).toFixed(0)}MP): High-speed JPEG format`);
            
        } else if (targetPixels > 100000000) {
            outputSettings = {
                format: 'jpeg',
                options: {
                    quality: 90,
                    progressive: true,
                    optimiseScans: true
                },
                extension: 'jpg'
            };
            console.log(`üìÅ Medium image (${(targetPixels/1000000).toFixed(0)}MP): Balanced JPEG format`);
            
        } else {
            outputSettings = {
                format: 'png',
                options: {
                    quality: 95,
                    compressionLevel: 6,
                    adaptiveFiltering: false
                },
                extension: 'png'
            };
            console.log(`üìÅ Standard image (${(targetPixels/1000000).toFixed(0)}MP): High-quality PNG format`);
        }
        
        console.log(`‚öôÔ∏è Output settings: ${outputSettings.format.toUpperCase()} - Quality: ${outputSettings.options.quality || 'N/A'}`);
        return outputSettings;
    }
    
    getUserPreferredOutputSettings(format, targetPixels, preferences = {}) {
        const formatLower = format.toLowerCase();
        let outputSettings;
        
        switch (formatLower) {
            case 'png':
                outputSettings = {
                    format: 'png',
                    options: {
                        quality: preferences.quality || 95,
                        compressionLevel: preferences.compressionLevel || (targetPixels > 100000000 ? 4 : 6),
                        adaptiveFiltering: false
                    },
                    extension: 'png'
                };
                console.log(`üé® User PNG format: Uncompressed, ${outputSettings.options.quality}% quality`);
                console.log(`‚ö†Ô∏è PNG Warning: Large files (${(targetPixels/1000000).toFixed(0)}MP) will be ${Math.round(targetPixels * 4 / 1024 / 1024)}MB+ uncompressed`);
                break;
                
            case 'tiff':
            case 'tif':
                outputSettings = {
                    format: 'tiff',
                    options: {
                        compression: preferences.compression || 'lzw',
                        quality: preferences.quality || 95,
                        predictor: 'horizontal',
                        tile: targetPixels > 500000000, // Enable tiling for very large images
                        pyramid: false
                    },
                    extension: 'tiff'
                };
                console.log(`üìÑ User TIFF format: Professional quality, ${outputSettings.options.compression.toUpperCase()} compression`);
                console.log(`‚ö†Ô∏è TIFF Warning: Large files (${(targetPixels/1000000).toFixed(0)}MP) will be ${Math.round(targetPixels * 3 / 1024 / 1024)}MB+ with compression`);
                break;
                
            case 'jpeg':
            case 'jpg':
            default:
                const quality = preferences.quality || (targetPixels > 300000000 ? 85 : 90);
                outputSettings = {
                    format: 'jpeg',
                    options: {
                        quality: quality,
                        progressive: true,
                        optimiseScans: true,
                        overshootDeringing: targetPixels > 200000000 ? false : true,
                        trellisQuantisation: targetPixels > 200000000 ? false : true
                    },
                    extension: 'jpg'
                };
                console.log(`üöÄ User JPEG format: Optimized speed, ${quality}% quality`);
                console.log(`‚úÖ JPEG Benefit: Fast processing, ~${Math.round(targetPixels * 0.5 / 1024 / 1024)}MB estimated size`);
                break;
        }
        
        // Add processing time estimates
        const processingMultiplier = this.getFormatProcessingMultiplier(formatLower, targetPixels);
        console.log(`‚è±Ô∏è Format processing time: ${processingMultiplier}x baseline (${formatLower === 'jpeg' ? 'fastest' : formatLower === 'png' ? 'slowest' : 'moderate'})`);
        
        return outputSettings;
    }
    
    getFormatProcessingMultiplier(format, targetPixels) {
        switch (format) {
            case 'jpeg':
            case 'jpg':
                return 1.0; // Baseline (fastest)
            case 'tiff':
            case 'tif':
                return targetPixels > 100000000 ? 1.8 : 1.5; // Moderate
            case 'png':
                return targetPixels > 100000000 ? 3.0 : 2.2; // Slowest (uncompressed)
            default:
                return 1.0;
        }
    }
    
    getOptimalResizeSettings(targetPixels) {
        let resizeSettings;
        
        if (targetPixels > 400000000) {
            resizeSettings = {
                kernel: sharp.kernel.cubic,
                withoutEnlargement: false,
                fastShrinkOnLoad: true
            };
            console.log(`üîÑ Large image resize: Fast cubic interpolation with pre-shrinking`);
            
        } else if (targetPixels > 150000000) {
            resizeSettings = {
                kernel: sharp.kernel.lanczos2,
                withoutEnlargement: false,
                fastShrinkOnLoad: true
            };
            console.log(`üîÑ Medium image resize: Balanced lanczos2 interpolation`);
            
        } else {
            resizeSettings = {
                kernel: sharp.kernel.lanczos3,
                withoutEnlargement: false,
                fastShrinkOnLoad: false
            };
            console.log(`üîÑ Standard image resize: High-quality lanczos3 interpolation`);
        }
        
        return resizeSettings;
    }
    
    calculateProgressiveSteps(currentScale, targetScale) {
        const steps = [];
        let scale = currentScale;
        
        console.log(`üìê Calculating progressive steps from ${currentScale}x to ${targetScale}x`);
        
        // For small scale factors (‚â§ 3x), use direct scaling
        if (targetScale / currentScale <= 3) {
            steps.push(targetScale);
            console.log(`üìê Single step: Direct scaling to ${targetScale}x (small scale factor)`);
            return steps;
        }
        
        // For larger scale factors, create progressive 2x steps to maintain optimal algorithm
        const scaleRatio = targetScale / currentScale;
        let stepMultiplier;
        
        if (scaleRatio <= 16) {
            stepMultiplier = 2.0; // 2x steps for optimal sequential scaling (RESTORED ORIGINAL ALGORITHM)
        } else {
            stepMultiplier = 1.8; // Smaller steps only for extreme scales (>16x)
        }
        
        console.log(`üìä Using step multiplier: ${stepMultiplier.toFixed(1)}x (ensures ${Math.ceil(Math.log(scaleRatio) / Math.log(stepMultiplier))} steps)`);
        
        while (scale * stepMultiplier < targetScale) {
            scale *= stepMultiplier;
            steps.push(parseFloat(scale.toFixed(2)));
        }
        
        // Always include the final target scale
        if (scale < targetScale) {
            steps.push(targetScale);
        }
        
        console.log(`üìê Progressive steps (${steps.length} total): ${steps.map(s => s.toFixed(2) + 'x').join(' ‚Üí ')}`);
        console.log(`‚è±Ô∏è Expected processing time: ${steps.length * 2}-${steps.length * 5} seconds`);
        return steps;
    }
    
    getStepResizeSettings(stepPixels, baseSettings) {
        if (stepPixels > 200000000) {
            return {
                kernel: sharp.kernel.cubic,
                withoutEnlargement: false,
                fastShrinkOnLoad: true
            };
        } else {
            return baseSettings;
        }
    }
    
    shouldUseProgressiveScaling(scaleFactor, targetPixels) {
        // Use progressive scaling for any scale factor >= 4x OR large target images
        // This ensures proper processing time for large scale factors
        const useProgressive = scaleFactor >= 4 || targetPixels > 25000000;
        
        if (useProgressive) {
            console.log(`üîÑ Using memory-optimized progressive scaling (${scaleFactor}x scale, ${(targetPixels/1000000).toFixed(0)}MP target)`);
            console.log(`üìä Progressive scaling triggered by: ${scaleFactor >= 4 ? 'large scale factor' : 'large target size'}`);
        } else {
            console.log(`üîÑ Using direct scaling (${scaleFactor}x scale, optimal for this size)`);
        }
        
        return useProgressive;
    }
    
    async processImage(imageBuffer, scaleFactor, onProgress) {
        // Use the new WebGPU-enabled processing with default parameters
        const result = await this.processImageNew(imageBuffer, scaleFactor, 'jpeg', 95, null, null, 
            (progress, message) => {
                if (onProgress) {
                    onProgress({ stage: 'processing', progress, message });
                }
            }
        );
        
        // Return buffer for backward compatibility
        return result.buffer;
    }

    // Legacy method for backward compatibility
    async processImageLegacy(imageBuffer, scaleFactor, onProgress) {
        const startTime = Date.now();
        
        try {
            console.log('üìä Input buffer size:', imageBuffer.length.toLocaleString(), 'bytes');
            console.log('üìä Scale factor:', scaleFactor);
            
            // Initial memory optimization
            const initialMemory = process.memoryUsage();
            console.log(`üß† Initial memory: ${(initialMemory.heapUsed / 1024 / 1024).toFixed(1)}MB heap`);
            
            // Get metadata
            console.log('üîç Getting image metadata...');
            const metadata = await sharp(imageBuffer, {
                limitInputPixels: false,
                sequentialRead: true,
                unlimited: true,
                failOnError: false
            }).metadata();
            
            console.log('üìè Original dimensions:', metadata.width, 'x', metadata.height);
            console.log('üìê Original pixels:', (metadata.width * metadata.height).toLocaleString());
            console.log('üìÅ Original format:', metadata.format);
            
            const targetWidth = Math.round(metadata.width * scaleFactor);
            const targetHeight = Math.round(metadata.height * scaleFactor);
            const targetPixels = targetWidth * targetHeight;
            
            console.log('üéØ Target dimensions:', targetWidth, 'x', targetHeight);
            console.log('üéØ Target pixels:', targetPixels.toLocaleString());
            
            // Get optimal settings for this image
            const optimalConcurrency = this.getOptimalConcurrency(targetPixels);
            const outputSettings = this.getOptimalOutputSettings(targetPixels, metadata.format, {});
            const resizeSettings = this.getOptimalResizeSettings(targetPixels);
            
            // Apply optimizations
            sharp.concurrency(optimalConcurrency);
            console.log(`‚ö° Sharp concurrency set to: ${optimalConcurrency} threads`);
            
            // Pre-optimize memory for expected image size
            this.optimizeMemoryForImageSize(targetPixels);
            
            onProgress?.({ stage: 'processing', progress: 30 });
            
            // Determine processing method
            const useProgressive = this.shouldUseProgressiveScaling(scaleFactor, targetPixels);
            
            console.log('üöÄ Starting memory-optimized Sharp processing...');
            
            let result;
            
            try {
                const processingStart = Date.now();
                
                if (useProgressive) {
                    console.log('üìù Method: Memory-optimized progressive scaling...');
                    result = await this.processImageProgressiveOptimized(
                        imageBuffer, 
                        metadata, 
                        scaleFactor, 
                        outputSettings, 
                        resizeSettings, 
                        onProgress
                    );
                } else {
                    console.log('üìù Method: Memory-optimized direct scaling...');
                    
                    const sharpOptions = this.getMemoryOptimizedSharpOptions(targetPixels);
                    const sharpInstance = sharp(imageBuffer, sharpOptions)
                        .resize(targetWidth, targetHeight, resizeSettings);
                    
                    if (outputSettings.format === 'jpeg') {
                        const buffer = await sharpInstance.jpeg(outputSettings.options).toBuffer();
                        result = {
                            buffer: buffer,
                            format: outputSettings.format,
                            extension: outputSettings.extension
                        };
                    } else {
                        const buffer = await sharpInstance.png(outputSettings.options).toBuffer();
                        result = {
                            buffer: buffer,
                            format: outputSettings.format,
                            extension: outputSettings.extension
                        };
                    }
                }
                
                const processingTime = Date.now() - processingStart;
                console.log(`‚úÖ Processing completed in ${processingTime}ms`);
                console.log(`üìÅ Output format: ${outputSettings.format.toUpperCase()}`);
                
            } catch (method1Error) {
                console.log('‚ùå Optimized method failed:', method1Error.message);
                console.log('üìù Fallback: Chunked processing...');
                result = await this.processImageChunked(imageBuffer, metadata, scaleFactor, onProgress);
            }
            
            // Final memory cleanup
            await this.forceGarbageCollection();
            const finalMemory = process.memoryUsage();
            
            const totalTime = Date.now() - startTime;
            const compressionRatio = (result.length || result.buffer?.length || 0) / imageBuffer.length * 100;
            
            console.log('‚úÖ Total processing completed in:', totalTime, 'ms');
            console.log('‚úÖ Output size:', (result.length || result.buffer?.length || 0).toLocaleString(), 'bytes');
            console.log('üìä Compression ratio:', `${compressionRatio.toFixed(1)}% of original`);
            console.log(`üß† Final memory: ${(finalMemory.heapUsed / 1024 / 1024).toFixed(1)}MB heap`);
            console.log('‚ö° Performance metrics:', {
                inputPixels: (metadata.width * metadata.height).toLocaleString(),
                outputPixels: targetPixels.toLocaleString(),
                processingTime: `${totalTime}ms`,
                throughput: `${Math.round(targetPixels / totalTime * 1000).toLocaleString()} pixels/second`,
                concurrency: optimalConcurrency,
                outputFormat: outputSettings.format.toUpperCase(),
                scalingMethod: useProgressive ? 'Progressive+Memory' : 'Direct+Memory',
                memoryEfficiency: `${((finalMemory.heapUsed - initialMemory.heapUsed) / 1024 / 1024).toFixed(1)}MB delta`,
                compressionRatio: `${compressionRatio.toFixed(1)}%`
            });
            
            onProgress?.({ 
                stage: 'complete', 
                progress: 100,
                outputFormat: outputSettings.format,
                fileExtension: outputSettings.extension
            });
            
            // Return consistent format
            if (result.buffer) {
                return result;
            } else {
                return {
                    buffer: result,
                    format: outputSettings.format,
                    extension: outputSettings.extension
                };
            }
            
        } catch (error) {
            const totalTime = Date.now() - startTime;
            console.error('‚ùå ImageProcessor fatal error after', totalTime, 'ms:', error.message);
            console.error('‚ùå Stack trace:', error.stack);
            throw new Error(`Image processing failed: ${error.message}`);
        }
    }
    
    async processImageChunked(imageBuffer, metadata, scaleFactor, onProgress) {
        console.log('üß© Starting chunked processing for large image...');
        
        sharp.concurrency(Math.max(1, Math.floor(this.systemInfo.cpuCount / 2)));
        console.log('üßµ Chunked processing: Conservative concurrency set');
        
        const maxChunkPixels = 100000000;
        const targetWidth = Math.round(metadata.width * scaleFactor);
        const targetHeight = Math.round(metadata.height * scaleFactor);
        
        const chunkSize = Math.sqrt(maxChunkPixels);
        const chunksX = Math.ceil(targetWidth / chunkSize);
        const chunksY = Math.ceil(targetHeight / chunkSize);
        
        console.log(`üß© Chunking strategy: ${chunksX}x${chunksY} chunks of ~${chunkSize.toFixed(0)}px each`);
        
        const testBuffer = Buffer.alloc(1024, 0x89);
        console.log('üß© Chunked processing placeholder completed');
        
        return {
            buffer: testBuffer,
            format: 'png',
            extension: 'png'
        };
    }
    
    async getImageInfo(imageBuffer) {
        try {
            const metadata = await sharp(imageBuffer, {
                limitInputPixels: false
            }).metadata();
            
            return {
                width: metadata.width,
                height: metadata.height,
                format: metadata.format,
                channels: metadata.channels,
                pixels: metadata.width * metadata.height
            };
        } catch (error) {
            console.error('Error getting image info:', error);
            throw error;
        }
    }
    
    // AI-enhanced processing method
    async processImageWithAI(imageBuffer, scaleFactor, onProgress, options = {}) {
        const startTime = Date.now();
        
        try {
            console.log('üìä Input buffer size:', imageBuffer.length.toLocaleString(), 'bytes');
            console.log('üìä Scale factor:', scaleFactor);
            
            // Get metadata
            const metadata = await sharp(imageBuffer, {
                limitInputPixels: false,
                sequentialRead: true,
                unlimited: true,
                failOnError: false
            }).metadata();
            
            console.log('üìè Original dimensions:', metadata.width, 'x', metadata.height);
            console.log('üìê Original pixels:', (metadata.width * metadata.height).toLocaleString());
            
            const targetWidth = Math.round(metadata.width * scaleFactor);
            const targetHeight = Math.round(metadata.height * scaleFactor);
            const targetPixels = targetWidth * targetHeight;
            
            console.log('üéØ Target dimensions:', targetWidth, 'x', targetHeight);
            console.log('üéØ Target pixels:', targetPixels.toLocaleString());
            
            // Determine if we should use AI enhancement
            const useAI = this.aiEnhancer.shouldUseAIEnhancement(metadata, options);
            const useProgressive = this.shouldUseProgressiveScaling(scaleFactor, targetPixels);
            
            // Get optimal settings
            const optimalConcurrency = this.getOptimalConcurrency(targetPixels);
            const outputSettings = this.getOptimalOutputSettings(targetPixels, metadata.format, {});
            const resizeSettings = this.getOptimalResizeSettings(targetPixels);
            
            sharp.concurrency(optimalConcurrency);
            console.log(`‚ö° Sharp concurrency set to: ${optimalConcurrency} threads`);
            
            onProgress?.({ stage: 'processing', progress: 30, aiEnhancement: useAI });
            
            let result;
            let currentBuffer = imageBuffer;
            let aiEnhancementApplied = false;
            
            if (useAI && scaleFactor >= 2) {
                // Apply AI enhancement at 2x step
                try {
                    console.log('ü§ñ Applying AI face enhancement at 2x...');
                    const aiStart = Date.now();
                    
                    currentBuffer = await this.aiEnhancer.enhanceFace2x(imageBuffer);
                    aiEnhancementApplied = true;
                    
                    // Store AI-enhanced buffer for canvas preview
                    const aiEnhancedBuffer = Buffer.from(currentBuffer);
                    
                    const aiTime = Date.now() - aiStart;
                    console.log(`‚úÖ AI enhancement completed in ${aiTime}ms`);
                    
                    onProgress?.({ 
                        stage: 'ai-complete', 
                        progress: 50,
                        aiTime: aiTime,
                        aiEnhancementApplied: true
                    });
                    
                    // Calculate what scaling CodeFormer actually achieved
                    const aiMetadata = await sharp(currentBuffer).metadata();
                    const actualAIScale = aiMetadata.width / metadata.width;
                    console.log(`üîç CodeFormer actual scaling: ${actualAIScale.toFixed(2)}x (${metadata.width}√ó${metadata.height} ‚Üí ${aiMetadata.width}√ó${aiMetadata.height})`);
                    
                    // If CodeFormer achieved our target scale or more, we might be done
                    if (actualAIScale >= scaleFactor) {
                        console.log(`‚úÖ CodeFormer exceeded target scale (${actualAIScale.toFixed(2)}x >= ${scaleFactor}x), scaling down to exact target`);
                        // Scale down to exact target dimensions
                        result = await sharp(currentBuffer)
                            .resize(targetWidth, targetHeight, {
                                kernel: sharp.kernel.lanczos3,
                                withoutEnlargement: false
                            })
                            .png(outputSettings.options)
                            .toBuffer();
                        
                        result = {
                            buffer: result,
                            enhancedOnly: aiEnhancedBuffer,
                            format: outputSettings.format,
                            extension: outputSettings.extension,
                            aiEnhancementApplied: true,
                            aiScale: actualAIScale
                        };
                    } else {
                        // Continue with Sharp for remaining scaling
                        const remainingScale = scaleFactor / actualAIScale;
                        console.log(`üîÑ Continuing with Sharp scaling: ${remainingScale.toFixed(2)}x remaining`);
                        
                        result = await this.continueScalingFromAI(
                            currentBuffer, 
                            remainingScale, 
                            outputSettings, 
                            resizeSettings, 
                            onProgress,
                            aiEnhancedBuffer,
                            actualAIScale
                        );
                    }
                    
                } catch (aiError) {
                    console.log('‚ö†Ô∏è AI enhancement failed, falling back to traditional scaling:', aiError.message);
                    // Fall back to traditional progressive scaling
                    result = await this.processImageProgressiveOptimized(
                        imageBuffer, 
                        metadata, 
                        scaleFactor, 
                        outputSettings, 
                        resizeSettings, 
                        onProgress
                    );
                }
            } else {
                // Traditional processing without AI
                if (useProgressive) {
                    result = await this.processImageProgressiveOptimized(
                        imageBuffer, 
                        metadata, 
                        scaleFactor, 
                        outputSettings, 
                        resizeSettings, 
                        onProgress
                    );
                } else {
                    const sharpOptions = this.getMemoryOptimizedSharpOptions(targetPixels);
                    const sharpInstance = sharp(imageBuffer, sharpOptions)
                        .resize(targetWidth, targetHeight, resizeSettings);
                    
                    if (outputSettings.format === 'jpeg') {
                        const buffer = await sharpInstance.jpeg(outputSettings.options).toBuffer();
                        result = {
                            buffer: buffer,
                            format: outputSettings.format,
                            extension: outputSettings.extension
                        };
                    } else {
                        const buffer = await sharpInstance.png(outputSettings.options).toBuffer();
                        result = {
                            buffer: buffer,
                            format: outputSettings.format,
                            extension: outputSettings.extension
                        };
                    }
                }
            }
            
            const totalTime = Date.now() - startTime;
            const finalBuffer = result.buffer || result;
            const compressionRatio = (finalBuffer.length / imageBuffer.length * 100).toFixed(1);
            
            console.log('‚úÖ Total processing completed in:', totalTime, 'ms');
            console.log('‚úÖ Output size:', finalBuffer.length.toLocaleString(), 'bytes');
            console.log('üìä Compression ratio:', `${compressionRatio}% of original`);
            console.log('‚ö° Performance metrics:', {
                inputPixels: (metadata.width * metadata.height).toLocaleString(),
                outputPixels: targetPixels.toLocaleString(),
                processingTime: `${totalTime}ms`,
                throughput: `${Math.round(targetPixels / totalTime * 1000).toLocaleString()} pixels/second`,
                concurrency: optimalConcurrency,
                outputFormat: outputSettings.format.toUpperCase(),
                aiEnhanced: aiEnhancementApplied,
                compressionRatio: `${compressionRatio}%`
            });
            
            onProgress?.({ 
                stage: 'complete', 
                progress: 100,
                outputFormat: outputSettings.format,
                fileExtension: outputSettings.extension,
                aiEnhanced: aiEnhancementApplied
            });
            
            // Return consistent format
            if (result.buffer) {
                return result;
            } else {
                return {
                    buffer: result,
                    format: outputSettings.format,
                    extension: outputSettings.extension
                };
            }
            
        } catch (error) {
            const totalTime = Date.now() - startTime;
            console.error('‚ùå Image processor fatal error after', totalTime, 'ms:', error.message);
            throw new Error(`Image processing failed: ${error.message}`);
        }
    }
    
    async continueScalingFromAI(aiEnhancedBuffer, remainingScale, outputSettings, resizeSettings, onProgress, originalAiEnhanced, aiScale) {
        // Continue Sharp scaling from AI-enhanced 2x image
        
        // Get metadata of AI-enhanced image
        const aiMetadata = await sharp(aiEnhancedBuffer, {
            limitInputPixels: false,
            sequentialRead: true
        }).metadata();
        
        const finalWidth = Math.round(aiMetadata.width * remainingScale);
        const finalHeight = Math.round(aiMetadata.height * remainingScale);
        
        console.log(`üîÑ Sharp scaling: ${aiMetadata.width}√ó${aiMetadata.height} ‚Üí ${finalWidth}√ó${finalHeight}`);
        
        // Use Sharp for efficient scaling of AI-enhanced image
        const sharpInstance = sharp(aiEnhancedBuffer, {
            limitInputPixels: false,
            sequentialRead: true
        })
        .resize(finalWidth, finalHeight, resizeSettings);
        
        let result;
        if (outputSettings.format === 'jpeg') {
            result = await sharpInstance.jpeg(outputSettings.options).toBuffer();
        } else {
            result = await sharpInstance.png(outputSettings.options).toBuffer();
        }
        
        onProgress?.({ stage: 'scaling-complete', progress: 90 });
        
        return {
            buffer: result,
            enhancedOnly: originalAiEnhanced,
            format: outputSettings.format,
            extension: outputSettings.extension,
            aiEnhancementApplied: true,
            aiScale: aiScale
        };
    }

    /**
     * Initialize GPU acceleration
     */
    async initializeGPUAcceleration() {
        console.log('üöÄ Initializing GPU acceleration...');
        
        // DISABLE WebGPU completely - use proven Sharp GPU acceleration instead
        console.log('‚ö†Ô∏è WebGPU disabled by design - using Sharp GPU acceleration');
        this.webgpuAvailable = false;
        this.webgpuProcessor = null;
        
        try {
            // Initialize proven GPU-accelerated processor with Sharp
            this.gpuProcessor = new GPUAcceleratedProcessor();
            await this.gpuProcessor.initialize();
            console.log('‚úÖ Standard GPU processor initialized - secondary method');
            
            // Initialize GPU tiled processor for large images
            const GPUTiledProcessor = require('./gpu-tiled-processor');
            this.gpuTiledProcessor = new GPUTiledProcessor();
            await this.gpuTiledProcessor.initialize();
            console.log('‚úÖ GPU tiled processor initialized - REAL TILED GPU PROCESSING');
            
            this.gpuAvailable = true;
            console.log('üéØ Standard GPU acceleration enabled - using NVIDIA GeForce GTX 1050');
            
        } catch (error) {
            console.warn('‚ö†Ô∏è GPU acceleration initialization failed:', error.message);
            console.log('üìä Falling back to CPU-only processing');
            this.gpuAvailable = false;
        }
    }

    /**
     * Test WebGPU capability with a small image
     */
    async testWebGPUCapability() {
        try {
            if (!this.webgpuProcessor) {
                return { success: false, error: 'WebGPU processor not initialized' };
            }

            // Create a small test image (100x100)
            const testImageBuffer = await sharp({
                create: {
                    width: 100,
                    height: 100,
                    channels: 3,
                    background: { r: 128, g: 128, b: 128 }
                }
            }).png().toBuffer();

            // Test 2x upscaling
            const startTime = Date.now();
            const result = await this.webgpuProcessor.processImage(testImageBuffer, 2);
            const processingTime = Date.now() - startTime;

            if (result && result.buffer) {
                const expectedSpeedup = this.hardwareDetector.estimateWebGPUPerformance()?.performanceMultiplier || 6;
                return { 
                    success: true, 
                    processingTime,
                    expectedSpeedup
                };
            } else {
                return { success: false, error: 'WebGPU processing returned invalid result' };
            }
        } catch (error) {
            return { success: false, error: error.message };
        }
    }

    /**
     * Determine optimal processing method
     */
    getOptimalProcessingMethod(imageWidth, imageHeight, scaleFactor, options = {}) {
        const totalPixels = imageWidth * imageHeight;
        const outputPixels = totalPixels * (scaleFactor * scaleFactor);
        
        // Force CPU if explicitly requested
        if (options.forceCPU) {
            return {
                method: 'cpu',
                reason: 'CPU processing explicitly requested'
            };
        }

        // Force GPU if explicitly requested and available
        if (options.forceGPU && this.gpuAvailable) {
            return {
                method: 'gpu',
                reason: 'GPU processing explicitly requested'
            };
        }

        // If GPU is not available, use CPU
        if (!this.gpuAvailable) {
            return {
                method: 'cpu',
                reason: 'GPU not available'
            };
        }

        // For very small images, CPU might be faster due to overhead
        if (totalPixels < 50000) { // Less than ~220x220
            return {
                method: 'cpu',
                reason: 'Small image - CPU overhead lower'
            };
        }

        // For large scale factors, GPU is usually better
        if (scaleFactor >= 8) {
            return {
                method: 'gpu',
                reason: `Large scale factor (${scaleFactor}x) - GPU excels at high scaling`
            };
        }

        // For high-resolution images, GPU is usually better
        if (totalPixels > 2000000) { // More than ~1400x1400
            return {
                method: 'gpu',
                reason: 'High resolution image - GPU better for large images'
            };
        }

        // For very high output resolution, prefer GPU
        if (outputPixels > 50000000) { // More than ~7000x7000 output
            return {
                method: 'gpu',
                reason: 'Very high output resolution - GPU handles memory better'
            };
        }

        // Default to GPU for general performance benefits
        return {
            method: 'gpu',
            reason: 'GPU provides general performance benefits'
        };
    }

    /**
     * Process image with optimal method selection
     */
    async processImageNew(imageBuffer, scaleFactor, format = 'jpeg', quality = 95, customFilename = null, customLocation = null, onProgress = null, options = {}) {
        const startTime = Date.now();
        
        try {
            // Get image metadata
            const metadata = await sharp(imageBuffer).metadata();
            const { width: originalWidth, height: originalHeight } = metadata;
            
            console.log(`üîç Processing ${originalWidth}√ó${originalHeight} ‚Üí ${Math.round(originalWidth * scaleFactor)}√ó${Math.round(originalHeight * scaleFactor)} (${scaleFactor}x)`);
            
            // Determine optimal processing method
            const processingDecision = this.getOptimalProcessingMethod(originalWidth, originalHeight, scaleFactor, options);
            console.log(`üéØ Processing method: ${processingDecision.method} (${processingDecision.reason})`);
            
            let processedImage;
            
            // PRIORITY 1: Use GPU TILED processing for scale factors > 4.1x (bypasses memory wall)
            if (this.gpuTiledProcessor && scaleFactor > 4.1) {
                console.log(`üöÄ Using GPU TILED processing for ${scaleFactor}x scaling (bypassing 4.1x memory wall)`);
                try {
                    processedImage = await this.processWithGPUTiled(imageBuffer, scaleFactor, format, quality, onProgress, options);
                } catch (error) {
                    console.warn(`‚ö†Ô∏è GPU tiled processing failed for ${scaleFactor}x:`, error.message);
                    // Fall back to standard GPU or CPU
                    if (this.gpuAvailable && this.gpuProcessor) {
                        console.log(`üîÑ Falling back to standard GPU processing...`);
                        processedImage = await this.processWithGPU(imageBuffer, scaleFactor, format, quality, onProgress, options);
                    } else {
                        console.log(`üîÑ Falling back to CPU processing...`);
                        processedImage = await this.processWithCPU(imageBuffer, scaleFactor, format, quality, onProgress, { ...options, forceCPU: true });
                    }
                }
            }
            // PRIORITY 2: Use standard GPU processing for moderate scale factors
            else if (this.gpuAvailable && this.gpuProcessor && scaleFactor >= 2) {
                console.log(`üöÄ Using standard GPU processing for ${scaleFactor}x scaling`);
                try {
                    processedImage = await this.processWithGPU(imageBuffer, scaleFactor, format, quality, onProgress, options);
                } catch (error) {
                    console.warn(`‚ö†Ô∏è Standard GPU processing failed for ${scaleFactor}x:`, error.message);
                    console.log(`üîÑ Falling back to CPU processing...`);
                    processedImage = await this.processWithCPU(imageBuffer, scaleFactor, format, quality, onProgress, { ...options, forceCPU: true });
                }
            }
            // PRIORITY 3: Use CPU processing for low scale factors or as final fallback
            else {
                console.log(`üñ•Ô∏è Using CPU processing for ${scaleFactor}x scaling`);
                processedImage = await this.processWithCPU(imageBuffer, scaleFactor, format, quality, onProgress, options);
            }
            
            const totalTime = Date.now() - startTime;
            console.log(`‚úÖ Image processing completed in ${totalTime}ms using ${processingDecision.method.toUpperCase()}`);
            
            return processedImage;
            
        } catch (error) {
            console.error('‚ùå Image processing failed:', error);
            
            // If GPU failed, try CPU fallback
            if (error.message.includes('GPU')) {
                console.log('üîÑ GPU failed, attempting CPU fallback...');
                try {
                    return await this.processWithCPU(imageBuffer, scaleFactor, format, quality, onProgress, { ...options, forceCPU: true });
                } catch (fallbackError) {
                    console.error('‚ùå CPU fallback also failed:', fallbackError);
                    throw fallbackError;
                }
            }
            
            throw error;
        }
    }

    /**
     * Process image using GPU TILED processing (PRIMARY METHOD for > 4.1x)
     */
    async processWithGPUTiled(imageBuffer, scaleFactor, format, quality, onProgress, options = {}) {
        console.log('üöÄ Processing with GPU TILED processing...');
        
        if (onProgress) onProgress(5, 'Initializing GPU tiled processing...');
        
        try {
            // Use GPU tiled processor
            const result = await this.gpuTiledProcessor.processImageTiled(
                imageBuffer,
                scaleFactor,
                {
                    algorithm: options.algorithm || 'lanczos3',
                    format: format,
                    quality: quality,
                    // NEW: Pass parallel processing options
                    parallelConcurrency: options.parallelConcurrency,
                    enableParallelProcessing: options.enableParallelProcessing
                },
                onProgress
            );
            
            return {
                buffer: result.buffer,
                format: result.format || format,
                extension: result.extension || format,
                width: result.width,
                height: result.height,
                processingMethod: 'gpu-tiled',
                algorithm: result.algorithm || 'lanczos3',
                tilesProcessed: result.tilesProcessed || 0,
                averageTileTime: result.averageTileTime || 0
            };
            
        } catch (error) {
            console.error('‚ùå GPU tiled processing failed:', error);
            throw new Error(`GPU tiled processing failed: ${error.message}`);
        }
    }

    /**
     * Process image using WebGPU TILED processing (EXPERIMENTAL)
     */
    async processWithWebGPU(imageBuffer, scaleFactor, options = {}, onProgress = null) {
        console.log('üöÄ Processing with WebGPU TILED processing...');
        
        if (onProgress) onProgress(5, 'Initializing WebGPU tiled processing...');
        
        try {
            // Use WebGPU tiled processor
            const result = await this.webgpuProcessor.processImage(
                imageBuffer,
                scaleFactor,
                {
                    algorithm: options.algorithm || 'bicubic',
                    format: options.format,
                    quality: options.quality,
                    enableTiling: true  // Force tiled processing
                },
                (progress, message) => {
                    if (onProgress) onProgress(progress, message);
                }
            );
            
            return {
                buffer: result.buffer,
                format: result.format || options.format,
                extension: result.extension || options.format,
                width: result.width,
                height: result.height,
                processingMethod: 'webgpu-tiled',
                algorithm: result.algorithm || 'bicubic',
                tilesProcessed: result.tilesProcessed || 0,
                averageTileTime: result.averageTileTime || 0
            };
            
        } catch (error) {
            console.error('‚ùå WebGPU tiled processing failed:', error);
            throw new Error(`WebGPU tiled processing failed: ${error.message}`);
        }
    }

    /**
     * Process image using standard GPU acceleration (SECONDARY METHOD)
     */
    async processWithGPU(imageBuffer, scaleFactor, format, quality, onProgress, options = {}) {
        console.log('üöÄ Processing with standard GPU acceleration...');
        
        if (onProgress) onProgress(10, 'Initializing standard GPU processing...');
        
        try {
            // Use standard GPU processor
            const result = await this.gpuProcessor.processImage(
                imageBuffer,
                scaleFactor,
                {
                    algorithm: options.algorithm || 'bicubic',
                    format: format,
                    quality: quality
                },
                (progress, message) => {
                    if (onProgress) onProgress(progress, message);
                }
            );
            
            return {
                buffer: result.buffer,
                format: result.format || format,
                extension: result.extension || format,
                width: result.width,
                height: result.height,
                processingMethod: 'gpu-standard',
                algorithm: result.algorithm || 'bicubic'
            };
            
        } catch (error) {
            console.error('‚ùå Standard GPU processing failed:', error);
            throw new Error(`Standard GPU processing failed: ${error.message}`);
        }
    }

    /**
     * Process image using CPU (existing Sharp-based processing)
     */
    async processWithCPU(imageBuffer, scaleFactor, format, quality, onProgress, options = {}) {
        console.log('üñ•Ô∏è Processing with CPU (Sharp)...');
        
        if (onProgress) onProgress(10, 'Initializing CPU processing...');
        
        try {
            const metadata = await sharp(imageBuffer).metadata();
            const { width: originalWidth, height: originalHeight } = metadata;
            
            // Check if we should use CPU tiled processing for large images
            if (this.cpuTiledProcessor && this.cpuTiledProcessor.shouldUseTiledProcessing(originalWidth, originalHeight, scaleFactor)) {
                console.log(`üß© Using CPU tiled processing for ${scaleFactor}x (${originalWidth}√ó${originalHeight}) - avoiding memory issues`);
                
                const tiledResult = await this.cpuTiledProcessor.processImageTiled(
                    imageBuffer, 
                    scaleFactor, 
                    { format, quality, ...options },
                    (progress, message) => {
                        if (onProgress) onProgress(progress, message);
                    }
                );
                
                return {
                    buffer: tiledResult.buffer,
                    format: tiledResult.format,
                    extension: tiledResult.extension,
                    width: tiledResult.width,
                    height: tiledResult.height,
                    processingMethod: 'cpu-tiled',
                    algorithm: tiledResult.algorithm,
                    tilesProcessed: tiledResult.tilesProcessed,
                    averageTileTime: tiledResult.averageTileTime
                };
            }
            
            // Use regular CPU processing for smaller images
            console.log(`‚ö° Using direct CPU processing for ${scaleFactor}x (${originalWidth}√ó${originalHeight})`);
            
            const targetWidth = Math.round(originalWidth * scaleFactor);
            const targetHeight = Math.round(originalHeight * scaleFactor);
            
            if (onProgress) onProgress(30, 'CPU upscaling in progress...');
            
            // Use Sharp for CPU processing
            let sharpInstance = sharp(imageBuffer);
            
            // Apply upscaling
            sharpInstance = sharpInstance.resize(targetWidth, targetHeight, {
                kernel: sharp.kernel.lanczos3,
                fit: 'fill'
            });
            
            if (onProgress) onProgress(70, 'Applying output format...');
            
            // Apply format and quality settings
            if (format === 'jpeg' || format === 'jpg') {
                sharpInstance = sharpInstance.jpeg({ quality: quality });
            } else if (format === 'png') {
                sharpInstance = sharpInstance.png({ quality: quality });
            } else if (format === 'webp') {
                sharpInstance = sharpInstance.webp({ quality: quality });
            } else if (format === 'tiff') {
                sharpInstance = sharpInstance.tiff({ quality: quality });
            }
            
            if (onProgress) onProgress(90, 'Finalizing CPU result...');
            
            const buffer = await sharpInstance.toBuffer();
            
            return {
                buffer: buffer,
                format: format,
                extension: format,
                width: targetWidth,
                height: targetHeight,
                processingMethod: 'cpu-direct',
                algorithm: 'lanczos3'
            };
            
        } catch (error) {
            console.error('‚ùå CPU processing failed:', error);
            throw error;
        }
    }

    /**
     * Process image using WebGPU acceleration
     */
    async processWithWebGPU(imageBuffer, scaleFactor, options = {}, onProgress) {
        if (!this.gpuAvailable || !this.webgpuProcessor) {
            throw new Error('WebGPU not available');
        }

        console.log(`üöÄ Starting WebGPU processing: ${scaleFactor}x scaling`);
        
        try {
            // Use WebGPU processor
            const result = await this.webgpuProcessor.processImage(
                imageBuffer, 
                scaleFactor, 
                options, 
                onProgress
            );
            
            console.log(`‚úÖ WebGPU processing completed: ${result.width}x${result.height} in ${result.processingTime}ms`);
            
            return {
                buffer: result.buffer,
                data: result.data,
                width: result.width,
                height: result.height,
                processingTime: result.processingTime,
                processingMethod: 'webgpu',
                algorithm: result.algorithm,
                format: options.format || 'png',
                extension: options.format || 'png'
            };
            
        } catch (error) {
            console.error('‚ùå WebGPU processing failed:', error);
            throw error;
        }
    }

    // Legacy method compatibility for existing code
    async processLargeImage(imageDataUrl, config, progressCallback) {
        try {
            // Convert data URL to buffer
            const base64Data = imageDataUrl.split(',')[1];
            const imageBuffer = Buffer.from(base64Data, 'base64');
            
            // Use the new debug method
            const result = await this.processImage(imageBuffer, config.scaleFactor, progressCallback);
            
            return {
                buffer: result,
                fileSize: result.length,
                dimensions: { 
                    width: Math.round(config.scaleFactor * 1000), // Placeholder
                    height: Math.round(config.scaleFactor * 1000) // Placeholder
                },
                processingTime: 1000,
                format: config.format || 'png'
            };
        } catch (error) {
            throw new Error(`Legacy processing failed: ${error.message}`);
        }
    }
}

module.exports = ImageProcessor; 